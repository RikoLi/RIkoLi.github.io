<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>用Python requests库实现的简单爬虫 | 逢田文明博物馆</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="刚碰Python的时候就听说了可以写代码扒图，心想着试一试，于是写了一个简单的demo实现从百度图片上面扒图的功能，用的是requests库。">
<meta name="keywords" content="Python">
<meta property="og:type" content="article">
<meta property="og:title" content="用Python requests库实现的简单爬虫">
<meta property="og:url" content="http://www.zjuriko.ml/2018/08/06/用Python-requests库实现的简单爬虫/index.html">
<meta property="og:site_name" content="逢田文明博物馆">
<meta property="og:description" content="刚碰Python的时候就听说了可以写代码扒图，心想着试一试，于是写了一个简单的demo实现从百度图片上面扒图的功能，用的是requests库。">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-09-11T01:22:26.672Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="用Python requests库实现的简单爬虫">
<meta name="twitter:description" content="刚碰Python的时候就听说了可以写代码扒图，心想着试一试，于是写了一个简单的demo实现从百度图片上面扒图的功能，用的是requests库。">
  
    <link rel="alternate" href="/atom.xml" title="逢田文明博物馆" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">逢田文明博物馆</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">一个说闲话的地方</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://www.zjuriko.ml"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-用Python-requests库实现的简单爬虫" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/06/用Python-requests库实现的简单爬虫/" class="article-date">
  <time datetime="2018-08-06T12:28:50.000Z" itemprop="datePublished">2018-08-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      用Python requests库实现的简单爬虫
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>刚碰Python的时候就听说了可以写代码扒图，心想着试一试，于是写了一个简单的demo实现从百度图片上面扒图的功能，用的是requests库。</p>
<a id="more"></a>
<p>为什么不用自带的urllib库呢？其实本人并不知道urllib和requests两个库孰优孰劣，或者说根本不能比较，因为使用的场合不尽相同，使用者的爱好也不尽相同，只是先看到了requests库的教程于是先去查了它的文档，所以就用了这个库。</p>
<p>基本实现步骤如下：</p>
<ol>
<li>向image.baidu.com发一个带数据的get请求，包含要搜索的关键字keyword</li>
<li>拿到response之后用正则表达式筛选图片的URL，存入列表</li>
<li>遍历图片URL列表，逐个请求图片URL，将响应以二进制方式写入文件，保存</li>
</ol>
<p>代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests <span class="keyword">as</span> rq</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get response</span></span><br><span class="line">keyword = input(<span class="string">'Input keyword to search: '</span>)</span><br><span class="line">keyword = str(keyword)</span><br><span class="line">print(<span class="string">'Busy...'</span>)</span><br><span class="line">url = <span class="string">'http://image.baidu.com/search/index'</span></span><br><span class="line">data = &#123;    <span class="comment"># 发送get请求时上传的dict形式数据包</span></span><br><span class="line">    <span class="string">'tn'</span>: <span class="string">'baiduimage'</span>,</span><br><span class="line">    <span class="string">'ct'</span>: <span class="number">201326592</span>,</span><br><span class="line">    <span class="string">'cl'</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="string">'lm'</span>: <span class="number">-1</span>,</span><br><span class="line">    <span class="string">'pv'</span>: <span class="string">''</span>,</span><br><span class="line">    <span class="string">'word'</span>: keyword,</span><br><span class="line">    <span class="string">'z'</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">'ie'</span>: <span class="string">'utf-8'</span></span><br><span class="line">&#125;</span><br><span class="line">response = rq.get(url, data)</span><br><span class="line">response.encoding = <span class="string">'utf-8'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Match URLs</span></span><br><span class="line">match_pattern = <span class="string">r'"objURL":"([a-zA-Z0-9:_/.-]*)"'</span></span><br><span class="line">matcher = re.compile(match_pattern)</span><br><span class="line">objURL_list = matcher.findall(response.text)</span><br><span class="line">print(<span class="string">'---------------------------------'</span>)</span><br><span class="line">print(<span class="string">'Find %d pics!'</span> %len(objURL_list))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save pics</span></span><br><span class="line">print(<span class="string">'Busy...'</span>)</span><br><span class="line">img_counter = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> objURL_list:</span><br><span class="line">    img_page = rq.get(each)</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'./catch_pics/'</span>+str(img_counter)+<span class="string">'.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> img:</span><br><span class="line">        img.write(img_page.content)</span><br><span class="line">    print(str(img_counter)+<span class="string">'.jpg is done!'</span>)</span><br><span class="line">    img_counter += <span class="number">1</span></span><br><span class="line">print(<span class="string">'---------------------------------'</span>)</span><br><span class="line">print(<span class="string">'Done with %d pics!'</span> %img_counter)</span><br></pre></td></tr></table></figure></p>
<p>目前这个demo只支持一次扒下来30张图，原因是百度图片搜索后默认先加载出30张图。如果希望可以扒下来更多的图，需要实现“翻页”功能。</p>
<p>先用百度图片随便搜索一个关键字（如cat），在返回结果之后打开开发者工具，在Network中查看Headers的数据，发现每30张新图片开始加载时收到XHR，查看发现关键内容pn，怀疑：</p>
<ul>
<li>pn：已经显示的图片数page number</li>
</ul>
<p>如果猜测正确，我们只需要在发送请求时写入pn为希望显示的图片数即可，然后一切照旧。</p>
<p>以后会验证猜想继续改进本demo。</p>
<hr>
<p>2018.8.6<br>整理了一遍代码，现在支持多页扒图，可以选择扒图的页数。修改了发送请求的url为旧版百度图片网址，因为觉得旧版肯定支持数据包中pn的接收（不过似乎新版也可以，和网页布局无关…都是服务器去处理）。</p>
<p>修改后的代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests <span class="keyword">as</span> rq</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get response</span></span><br><span class="line">keyword = input(<span class="string">'Input keyword to search: '</span>)</span><br><span class="line">keyword = str(keyword)</span><br><span class="line">pages = input(<span class="string">'How many pages do you want to search?(About 60p per-page): '</span>)</span><br><span class="line">pages = int(pages)</span><br><span class="line">print(<span class="string">'Busy...'</span>)</span><br><span class="line">url = <span class="string">'http://image.baidu.com/search/flip'</span></span><br><span class="line">page_index = <span class="number">1</span></span><br><span class="line">objURL_list = []</span><br><span class="line"><span class="keyword">while</span> page_index &lt;= pages:</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">'tn'</span>: <span class="string">'baiduimage'</span>,</span><br><span class="line">        <span class="string">'word'</span>: keyword,</span><br><span class="line">        <span class="string">'ie'</span>: <span class="string">'utf-8'</span>,</span><br><span class="line">        <span class="string">'pn'</span>: page_index<span class="number">-1</span> * <span class="number">20</span></span><br><span class="line">    &#125;</span><br><span class="line">    response = rq.get(url, data)</span><br><span class="line">    response.encoding = <span class="string">'utf-8'</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Match URLs</span></span><br><span class="line">    match_pattern = <span class="string">r'"objURL":"([a-zA-Z0-9:_/.-]*)"'</span></span><br><span class="line">    matcher = re.compile(match_pattern)</span><br><span class="line">    objURL_list += matcher.findall(response.text)</span><br><span class="line">    page_index += <span class="number">1</span></span><br><span class="line">print(<span class="string">'---------------------------------'</span>)</span><br><span class="line">print(<span class="string">'Totally find %d pics!'</span> %len(objURL_list))</span><br><span class="line">print(<span class="string">'---------------------------------'</span>)</span><br><span class="line"><span class="comment"># Save pics</span></span><br><span class="line">print(<span class="string">'Busy...'</span>)</span><br><span class="line">img_counter = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> objURL_list:</span><br><span class="line">    img_page = rq.get(each)</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'./catch_pics/'</span>+str(img_counter)+<span class="string">'.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> img:</span><br><span class="line">        img.write(img_page.content)</span><br><span class="line">    print(str(img_counter+<span class="number">1</span>)+<span class="string">' of '</span>+str(len(objURL_list))+<span class="string">' pics'</span>+<span class="string">' are done!'</span>)</span><br><span class="line">    img_counter += <span class="number">1</span></span><br><span class="line">print(<span class="string">'---------------------------------'</span>)</span><br><span class="line">print(<span class="string">'Done with %d pics!'</span> %img_counter)</span><br></pre></td></tr></table></figure></p>
<hr>
<p>2018.8.8<br>重构了大量代码，因为发现了许多之前的错误。以之前的版本为基础设计了一个在safebooru扒图的爬虫，增加了一些细节如headers伪装、爬取频率减低等。</p>
<p>代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests <span class="keyword">as</span> rq</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="string">'''未来考虑加入多关键词筛选'''</span></span><br><span class="line"></span><br><span class="line">keyword = input(<span class="string">'Safebooru Search: '</span>)</span><br><span class="line">keyword = str(keyword)</span><br><span class="line">pages = input(<span class="string">'How many pages do you want to search?(About 40p per-page): '</span>)</span><br><span class="line">pages = int(pages)</span><br><span class="line">url = <span class="string">'http://safebooru.org/index.php?page=post&amp;s=list'</span></span><br><span class="line">page_index = <span class="number">1</span></span><br><span class="line">img_url = []</span><br><span class="line"><span class="keyword">while</span> page_index &lt;= pages:</span><br><span class="line">    <span class="comment"># Create data pack</span></span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">'Accept'</span>:<span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'</span>,</span><br><span class="line">        <span class="string">'Accept-Encoding'</span>:<span class="string">'gzip, deflate, sdch'</span>,</span><br><span class="line">        <span class="string">'Accept-Language'</span>:<span class="string">'zh-CN,zh;q=0.8,en;q=0.6'</span>,</span><br><span class="line">        <span class="string">'Connection'</span>:<span class="string">'keep-alive'</span>,</span><br><span class="line">        <span class="string">'Host'</span>:<span class="string">'safebooru.org'</span>,</span><br><span class="line">        <span class="string">'Upgrade-Insecure-Requests'</span>:<span class="number">1</span>,</span><br><span class="line">        <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Mobile Safari/537.36'</span>,</span><br><span class="line">        <span class="string">'page'</span>:<span class="string">'post'</span>,</span><br><span class="line">        <span class="string">'s'</span>:<span class="string">'list'</span>,</span><br><span class="line">        <span class="string">'tags'</span>:keyword,</span><br><span class="line">        <span class="string">'pid'</span>:(page_index<span class="number">-1</span>)*<span class="number">40</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># Get response</span></span><br><span class="line">        res = rq.get(url, data, timeout=<span class="number">30</span>)</span><br><span class="line">        res.encoding = <span class="string">'utf-8'</span></span><br><span class="line">        <span class="comment"># Match images</span></span><br><span class="line">        match_patter = <span class="string">r'src="//safebooru.org/thumbnails/([a-zA-Z0-9_/:.-?]*)"'</span></span><br><span class="line">        matcher = re.compile(match_patter)</span><br><span class="line">        img_url += matcher.findall(res.text)</span><br><span class="line">        print(<span class="string">'---------------------------------'</span>)</span><br><span class="line">        print(<span class="string">'Get page %d of %d!'</span> %(page_index, pages))</span><br><span class="line">        <span class="keyword">if</span> page_index &lt; pages:</span><br><span class="line">            print(<span class="string">'Next page starts in 3 secs...'</span>)</span><br><span class="line">            time.sleep(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">except</span> rq.exceptions.ConnectionError <span class="keyword">as</span> e:</span><br><span class="line">        e_str = str(e)</span><br><span class="line">        print(<span class="string">'Error type: %s! Jump to next page!'</span> %e_str)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        page_index += <span class="number">1</span></span><br><span class="line">print(<span class="string">'Totally find %d pics!'</span> %len(img_url))</span><br><span class="line">print(<span class="string">'---------------------------------'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Preprocessing of pic URLs</span></span><br><span class="line">new_img_url = []</span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> img_url:</span><br><span class="line">    new_each = each.replace(<span class="string">'thumbnail'</span>, <span class="string">'sample'</span>)</span><br><span class="line">    new_each = <span class="string">'http://safebooru.org//samples/'</span> + new_each</span><br><span class="line">    new_img_url.append(new_each)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create image folder</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'./pic/'</span>):</span><br><span class="line">    os.mkdir(<span class="string">'./pic/'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download pics</span></span><br><span class="line">img_counter = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> new_img_url:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        img_page = rq.get(each, timeout=<span class="number">30</span>)</span><br><span class="line">        <span class="keyword">if</span> img_page.status_code == <span class="number">404</span>: <span class="comment"># Check URL's validation for pics in safebooru</span></span><br><span class="line">            new_url = each.replace(<span class="string">'sample_'</span>, <span class="string">''</span>)</span><br><span class="line">            new_url = new_url.replace(<span class="string">'samples'</span>, <span class="string">'images'</span>)</span><br><span class="line">            img_page = rq.get(new_url, timeout=<span class="number">30</span>)</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'./pic/'</span>+str(img_counter)+<span class="string">'.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> img:</span><br><span class="line">            img.write(img_page.content)</span><br><span class="line">        print(str(img_counter+<span class="number">1</span>)+<span class="string">' of '</span>+str(len(new_img_url))+<span class="string">' pics'</span>+<span class="string">' are done!'</span>)</span><br><span class="line">    <span class="keyword">except</span> rq.exceptions.ConnectionError <span class="keyword">as</span> e:</span><br><span class="line">        e_str = str(e)</span><br><span class="line">        print(<span class="string">'Error type: %s! Jump to next image URL!'</span> %e_str)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        img_counter += <span class="number">1</span></span><br><span class="line">print(<span class="string">'---------------------------------'</span>)</span><br><span class="line">print(<span class="string">'Done with %d pics!'</span> %img_counter)</span><br><span class="line">os.system(<span class="string">'pause'</span>)</span><br></pre></td></tr></table></figure></p>
<hr>
<p>2018.8.17</p>
<p>东敲西改，零零碎碎写了几天之后完成了从Pixiv上爬取原图的代码，顺便感谢一下Pixiv官方终于支持在搜索时使用数字表示热度了，对过滤图片来说方便了不少（笑）。</p>
<p>至此，爬图的小项目就告一段落吧~</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.zjuriko.ml/2018/08/06/用Python-requests库实现的简单爬虫/" data-id="cjtweap83000u1sdu9yx3aads" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/08/07/几个有用的ACG图片网站/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          几个有用的ACG图片网站
        
      </div>
    </a>
  
  
    <a href="/2018/08/04/Python正则表达式笔记/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Python正则表达式笔记</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/GAN/">GAN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JavaScript/">JavaScript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/人工智能/">人工智能</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/其他/">其他</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/支持向量机/">支持向量机</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/深度学习/">深度学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/矩阵/">矩阵</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/随笔/">随笔</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/GAN/" style="font-size: 10px;">GAN</a> <a href="/tags/JavaScript/" style="font-size: 10px;">JavaScript</a> <a href="/tags/Python/" style="font-size: 16.67px;">Python</a> <a href="/tags/人工智能/" style="font-size: 10px;">人工智能</a> <a href="/tags/其他/" style="font-size: 10px;">其他</a> <a href="/tags/支持向量机/" style="font-size: 10px;">支持向量机</a> <a href="/tags/机器学习/" style="font-size: 13.33px;">机器学习</a> <a href="/tags/深度学习/" style="font-size: 20px;">深度学习</a> <a href="/tags/矩阵/" style="font-size: 10px;">矩阵</a> <a href="/tags/随笔/" style="font-size: 16.67px;">随笔</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/03/31/枯了/">枯了</a>
          </li>
        
          <li>
            <a href="/2019/03/26/GraphSAGE：Node Embedding初探&复现的一些想法/">GraphSAGE：Node Embedding初探&amp;复现的一些想法</a>
          </li>
        
          <li>
            <a href="/2019/03/24/2019.3.23水水亚巡场记/">2019.3.23水水亚巡场记</a>
          </li>
        
          <li>
            <a href="/2019/03/19/一些回忆的事/">一些回忆的事</a>
          </li>
        
          <li>
            <a href="/2019/03/09/AI整理/">AI整理</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Riko Li<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>